Metadata-Version: 2.4
Name: langmet
Version: 0.1.0
Summary: Observability and performance metrics for LLM and RAG systems
Author: Dr Mabrouka Abuhmida
License: MIT
Keywords: llm,rag,analytics,metrics,observability
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Provides-Extra: sqlalchemy
Requires-Dist: sqlalchemy>=2.0.23; extra == "sqlalchemy"
Provides-Extra: fastapi
Requires-Dist: fastapi>=0.104.1; extra == "fastapi"
Requires-Dist: pydantic>=2.5.0; extra == "fastapi"
Provides-Extra: dev
Requires-Dist: pytest>=8.0.0; extra == "dev"
Requires-Dist: ruff>=0.7.0; extra == "dev"
Requires-Dist: build>=1.2.2; extra == "dev"
Requires-Dist: twine>=5.1.1; extra == "dev"
Dynamic: license-file

# LangMet


**Observability and drift intelligence for LLM and RAG systems.**

LangMet provides a reusable analytics layer for monitoring operational performance, retrieval quality, and evidence coverage in AI systems.

It separates analytical computation from data access, allowing teams to compute metrics from any telemetry source â€” SQL databases, log streams, data warehouses, or custom repositories.

**Designed for production AI environments.**

LangMet separates **analytical intelligence** from data access so you can compute metrics from any source: SQL databases, log streams, files, or custom repositories.

# Why LangMet?

Most LLM metrics pipelines are tightly coupled to infrastructure.

# LangMet:

* isolates analytics from storage
* provides percentile-based latency monitoring
* supports windowed drift detection (short-term vs long-term baselines)
* enables evidence coverage analysis for RAG systems
* works with any data source via repository interfaces

**This makes it suitable for:**

* production monitoring
* research evaluation
* safety-critical AI systems
* regulated environments

## Features

- Pure analytics functions for:
  - Operational LLM metrics
  - RAG performance metrics
  - Citation coverage metrics
- Built-in latency percentiles (`p50`, `p90`, `p95`, `p99`) for SLO monitoring
- Drift detection for numeric and categorical signals (PSI + TVD based)
- Windowed drift baselines (compare last 1h vs trailing 7d automatically)
- Repository interface (`MetricsRepository`) for pluggable data access
- SQLAlchemy adapter for existing relational schemas
- Framework-agnostic service layer

## Install

```bash
pip install langmet
```

With SQLAlchemy adapter support:

```bash
pip install "langmet[sqlalchemy]"
```

## 2-Minute Demo

Most engineers want proof it works before reading internals. A runnable backend + frontend demo is included:

- `examples/two-minute-demo/README.md`

Quick run:

```bash
python -m pip install -e ".[fastapi]"
python -m pip install uvicorn
uvicorn app:app --app-dir examples/two-minute-demo --reload
```

Open `http://127.0.0.1:8000/`.

### Demo Preview

![LangMet Demo UI](docs/assets/langmet-demo.gif)

> If the GIF does not render in your GitHub client, use the static screenshot below.

![LangMet Demo Screenshot](docs/assets/langmet-demo.png)

## Quickstart (Pure Functions)

```python
from datetime import datetime
from langmet.models import CompletionEvent
from langmet.analytics import compute_operational_metrics

events = [
    CompletionEvent(
        provider="openai",
        model="gpt-4o-mini",
        latency_ms=320,
        tokens_total=850,
        error_message=None,
        created_at=datetime.utcnow(),
    )
]

metrics = compute_operational_metrics(events)
print(metrics["overview"]["avg_latency_ms"])
```

Drift detection:

```python
from datetime import datetime, timedelta
from langmet.analytics import (
    detect_numeric_drift,
    detect_categorical_drift,
    detect_numeric_drift_windowed,
)

latency_drift = detect_numeric_drift(
    baseline_values=[120, 130, 115, 125],
    current_values=[210, 220, 205, 215],
)

provider_drift = detect_categorical_drift(
    baseline_labels=["openai", "openai", "anthropic"],
    current_labels=["anthropic", "anthropic", "openai"],
)

# Automatic window split: last 1h vs trailing 7d.
ref = datetime.utcnow()
observations = [
    (ref - timedelta(hours=2), 120.0),
    (ref - timedelta(minutes=40), 220.0),
]
windowed_drift = detect_numeric_drift_windowed(
    observations=observations,
    reference_time=ref,
)
```

## Quickstart (Repository + Service)

```python
from datetime import datetime, timedelta
from langmet.service import AnalyticsService
from langmet.adapters.sqlalchemy_repo import SQLAlchemyMetricsRepository

repo = SQLAlchemyMetricsRepository(db_session)
service = AnalyticsService(repo)

start = datetime.utcnow() - timedelta(days=7)
end = datetime.utcnow()

all_operational = service.get_operational_metrics(start, end)
all_rag = service.get_rag_metrics(start, end)
citation = service.get_citation_coverage(start, end)
```

## Core Concepts

- `langmet.models`: event contracts used by analytics
- `langmet.analytics`: pure computation functions
- `langmet.ports`: repository protocol your project can implement
- `langmet.service`: orchestration facade
- `langmet.adapters`: optional infrastructure adapters

## Development

```bash
pip install -e ".[dev,sqlalchemy]"
ruff check .
pytest
python -m build
twine check dist/*
```

## License

MIT
